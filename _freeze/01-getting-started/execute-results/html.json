{
  "hash": "429c13ef96f52226a5a8e106d009ab62",
  "result": {
    "engine": "knitr",
    "markdown": "# Getting started with R & RStudio {#sec-chap01}\n\n\n\n\n\n\n## Table of content for chapter 01\n\n::::: {#obj-chap01}\n:::: {.my-objectives}\n::: {.my-objectives-header}\nChapter section list\n:::\n\n::: {.my-objectives-container}\n\n-   ~~Working with RStudio projects~~ (@sec-chap01-1)\n-   R Basics (@sec-chap01-2)\n-   Fixing errors and getting help (@sec-chap01-3)\n-   ~~Organizing your work and making it reproducible~~ (@sec-chap01-4)\n-   An Extended Illustration: Duncan's Occupational-Prestige Regression (@sec-chap01-5)\n\n\n\n:::\n::::\n:::::\n\n## Working with RStudio projects (empty) {#sec-chap01-1}\n\n## R Basics {#sec-chap01-2}\n\n- A novel feature of the R help system is the facility it provides to execute most examples in the help pages via the example() command: \n$$example ('log')$$\n\n- A quick way to determine the arguments of an R function is to use the `args()` function:\n$$args ('log')$$\n\n::: {.callout-warning #wrn-help-generig-functions}\nThe `args()` and `help()` functions may not be very helpful with generic functions.\n:::\n\n- For the full set of reserved symbols in R, see \n$$help ('Reserved')$$\n\n- There are two types of logical operators: \n    - vectorizes: $\\&$ and $|$ vectorized resp. \n    - single operand: $\\&\\&$ and $||$\n    \nThe unvectorized versions of the *and* (&&) and *or* (||) operators are primarily useful for writing R programs and are not appropriate for indexing vectors.\n\n## Fixing errors and getting help {#sec-chap01-3}\n\n:::{.my-bulletbox}\n:::: {.my-bulletbox-header}\n::::: {.my-bulletbox-icon}\n:::::\n:::::: {#bul-getting-help}\n::::::\n: Getting help\n::::\n:::: {.my-bulletbox-body}\n- `base::traceback()` provides information about the sequence of function calls leading up to an error.\n- `utils::apropos('<searchString>')` searches for currently accessible objects whose names contain a particular character string. It returns a character vector giving the names of objects in the search list matching (as a regular expression)\n- `utils:find('<searchString>')` returns where objects of a given name can be found.\n- `??` or `help.search()` activates a broader search because it looks not only in the title fields but in other fields of the help pages as well.\n- `utils::RSiteSearch()` or the search engine at https://search.r-project.org/ needs an internet connection and starts a search even broader. It looks in all standard and CRAN packages, even those not installed on your system.\n- [CRAN task views](https://cran.r-project.org/web/views/) describe\tresources in R for applications in specific areas.\n    - Views can be installed automatically via ctv::install.views(\"Bayesian\") or ctv::update.views(\"Bayesian\", coreOnly=TRUE)\n    - Query information about a particular task view on CRAN from within R for example with `ctv::ctv(\"MachineLearning\")`\n    - Query to obtain the list of all task views available with `ctv::available.views()`\n- `help(package='<packageName>')` calls the index help page of an installed package in the RStudio Help tab, including the hyperlinked index of help topics documented in the package.\n- <a class='glossary' title='A vignette is a long-form guide to your package. (Chapter Vignettes in R Packages 2e)'>Vignette</a>:\n    - `utils::vignette()` lists available vignettes in the packages installed on your system in the code window. \n    - `utils::browseVignettes()` open a local web page listing vignettes in the packages installed on your system\n    - `utils::vignette(package='<packageName>')` displays the vignettes available in a particular installed package. \n    - `vignette('vignetteName')` or vignette('<vignetteName>', package='<packageName>') opens a specific vignette.\n- *RStudio help*: \n    - Menu \"Help > R Help\" opens  an overview page with R resources\n    - Search R help with shortcut CTRL-ALT-F1\n    - [Finding your way to R](https://education.rstudio.com/learn/) with three learning pathes: [Beginners](https://education.rstudio.com/learn/beginner/), [Intermediates](https://education.rstudio.com/learn/intermediate/) and [Experts](https://education.rstudio.com/learn/expert/)\n- *Google search*\n- <a class='glossary' title='Stack Overflow is a question-and-answer website for computer programmers. (Wikipedia)'>StackOverflow</a> and <a class='glossary' title='Cross Validated is a question and answer site for people interested in statistics, machine learning, data analysis, data mining, and data visualization. It is built and run by you as part of the Stack Exchange network of Q&amp;A sites. (StackExchange)'>Cross Validated</a>: \n    - [Stack Overflow](https://stackoverflow.com/) is a question and answer site for professional and enthusiast programmers. \n    - [Cross Validated](https://stats.stackexchange.com/) is a question and answer site for people interested in statistics, machine learning, data analysis, data mining, and data visualization.\n\n::::\n:::\n\n\n\n## Organizing your work and making it reproducible (empty) {#sec-chap01-4}\n\n## An Extended Illustration {#sec-chap01-5}\n\n### Getting, recoding and showing data\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap01-illustration}\n: Duncan's Occupational-Prestige Regression\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### get data\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-show-duncan-data}\n: Show Duncan raw data from {**carData**} package\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap01-get-duncan-data}\n\n::: {.cell}\n\n```{.r .cell-code}\ncarData::Duncan\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                    type income education prestige\n#> accountant         prof     62        86       82\n#> pilot              prof     72        76       83\n#> architect          prof     75        92       90\n#> author             prof     55        90       76\n#> chemist            prof     64        86       90\n#> minister           prof     21        84       87\n#> professor          prof     64        93       93\n#> dentist            prof     80       100       90\n#> reporter             wc     67        87       52\n#> engineer           prof     72        86       88\n#> undertaker         prof     42        74       57\n#> lawyer             prof     76        98       89\n#> physician          prof     76        97       97\n#> welfare.worker     prof     41        84       59\n#> teacher            prof     48        91       73\n#> conductor            wc     76        34       38\n#> contractor         prof     53        45       76\n#> factory.owner      prof     60        56       81\n#> store.manager      prof     42        44       45\n#> banker             prof     78        82       92\n#> bookkeeper           wc     29        72       39\n#> mail.carrier         wc     48        55       34\n#> insurance.agent      wc     55        71       41\n#> store.clerk          wc     29        50       16\n#> carpenter            bc     21        23       33\n#> electrician          bc     47        39       53\n#> RR.engineer          bc     81        28       67\n#> machinist            bc     36        32       57\n#> auto.repairman       bc     22        22       26\n#> plumber              bc     44        25       29\n#> gas.stn.attendant    bc     15        29       10\n#> coal.miner           bc      7         7       15\n#> streetcar.motorman   bc     42        26       19\n#> taxi.driver          bc      9        19       10\n#> truck.driver         bc     21        15       13\n#> machine.operator     bc     21        20       24\n#> barber               bc     16        26       20\n#> bartender            bc     16        28        7\n#> shoe.shiner          bc      9        17        3\n#> cook                 bc     14        22       16\n#> soda.clerk           bc     12        30        6\n#> watchman             bc     17        25       11\n#> janitor              bc      7        20        8\n#> policeman            bc     34        47       41\n#> waiter               bc      8        32       10\n```\n\n\n:::\n:::\n\n\nDuncan raw data from {**carData**} package\n\n:::\n\n***\nThe row names contains data and have to be therefore a separate column.\n\n\n::::\n:::::\n\n\n###### recode \n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-recode-duncan-data}\n: Recode Duncan data\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap01-recode-duncan-data}    \n\n::: {.cell}\n\n```{.r .cell-code}\n(d_01 <- carData::Duncan |> \n    tibble::rownames_to_column(\"occupation\"))\n\nsave_data_file(\"chap01\", d_01, \"d_01.rds\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>            occupation type income education prestige\n#> 1          accountant prof     62        86       82\n#> 2               pilot prof     72        76       83\n#> 3           architect prof     75        92       90\n#> 4              author prof     55        90       76\n#> 5             chemist prof     64        86       90\n#> 6            minister prof     21        84       87\n#> 7           professor prof     64        93       93\n#> 8             dentist prof     80       100       90\n#> 9            reporter   wc     67        87       52\n#> 10           engineer prof     72        86       88\n#> 11         undertaker prof     42        74       57\n#> 12             lawyer prof     76        98       89\n#> 13          physician prof     76        97       97\n#> 14     welfare.worker prof     41        84       59\n#> 15            teacher prof     48        91       73\n#> 16          conductor   wc     76        34       38\n#> 17         contractor prof     53        45       76\n#> 18      factory.owner prof     60        56       81\n#> 19      store.manager prof     42        44       45\n#> 20             banker prof     78        82       92\n#> 21         bookkeeper   wc     29        72       39\n#> 22       mail.carrier   wc     48        55       34\n#> 23    insurance.agent   wc     55        71       41\n#> 24        store.clerk   wc     29        50       16\n#> 25          carpenter   bc     21        23       33\n#> 26        electrician   bc     47        39       53\n#> 27        RR.engineer   bc     81        28       67\n#> 28          machinist   bc     36        32       57\n#> 29     auto.repairman   bc     22        22       26\n#> 30            plumber   bc     44        25       29\n#> 31  gas.stn.attendant   bc     15        29       10\n#> 32         coal.miner   bc      7         7       15\n#> 33 streetcar.motorman   bc     42        26       19\n#> 34        taxi.driver   bc      9        19       10\n#> 35       truck.driver   bc     21        15       13\n#> 36   machine.operator   bc     21        20       24\n#> 37             barber   bc     16        26       20\n#> 38          bartender   bc     16        28        7\n#> 39        shoe.shiner   bc      9        17        3\n#> 40               cook   bc     14        22       16\n#> 41         soda.clerk   bc     12        30        6\n#> 42           watchman   bc     17        25       11\n#> 43            janitor   bc      7        20        8\n#> 44          policeman   bc     34        47       41\n#> 45             waiter   bc      8        32       10\n```\n\n\n:::\n:::\n\n\nDuncan data recoded\n:::\n\n***\n\nDuncan was interested in how `prestige` is related to `income` and `education` in combination.\n\n::::\n:::::\n\n###### skim data\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-skim-duncan}\n: Skim Duncan data\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap01-skim-duncan}\n\n::: {.cell}\n\n```{.r .cell-code}\nskimr::skim(d_01)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |d_01 |\n|Number of rows           |45   |\n|Number of columns        |5    |\n|_______________________  |     |\n|Column type frequency:   |     |\n|character                |1    |\n|factor                   |1    |\n|numeric                  |3    |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|occupation    |         0|             1|   4|  18|     0|       45|          0|\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts             |\n|:-------------|---------:|-------------:|:-------|--------:|:----------------------|\n|type          |         0|             1|FALSE   |        3|bc: 21, pro: 18, wc: 6 |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|  mean|    sd| p0| p25| p50| p75| p100|hist  |\n|:-------------|---------:|-------------:|-----:|-----:|--:|---:|---:|---:|----:|:-----|\n|income        |         0|             1| 41.87| 24.44|  7|  21|  42|  64|   81|▇▂▅▃▅ |\n|education     |         0|             1| 52.56| 29.76|  7|  26|  45|  84|  100|▆▆▃▂▇ |\n|prestige      |         0|             1| 47.69| 31.51|  3|  16|  41|  81|   97|▇▃▅▂▇ |\n\n\n:::\n:::\n\n\nLook at the recoded Duncan data\n:::\n\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\n### Explorative Data Analysis\n\nDuncan used a linear least-squares regression of `prestige` on `income` and `education` to predict the prestige of occupations for which the income and educational scores were known from the U.S. Census but for which there were no direct prestige ratings. He did not use occupational type in his analysis.\n\nA sensible place to start any data analysis, including a regression analysis, is to visualize the data using a variety of graphical displays. We need the following graphs:\n\n- Univariate distributions of the three variables\n- Pairwise or marginal relationships among them\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap01-eda}\n: Explorative Data Analysis (EDA) of Duncan data\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### hist prestige\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-hist-prestige}\n: Histogram of `prestige` variable\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap01-hist-prestige}\n\n::: {.cell}\n\n```{.r .cell-code}\nd_01 |> \n    ggplot2::ggplot(\n        ggplot2::aes(x = prestige)\n    ) +\n    ggplot2::geom_histogram(\n        bins = 10,\n        color = \"white\",\n        fill = \"grey40\")\n```\n\n::: {.cell-output-display}\n![](01-getting-started_files/figure-html/hist-prestige-1.png){width=672}\n:::\n:::\n\nHistogram of prestige variable\n:::\n\n***\nThe distribution of `prestige` appears to be bimodal, with cases stacking up near the boundaries, as many occupations are either low prestige, near the lower boundary, or high prestige, near the upper boundary, with relatively fewer occupations in the middle bins of the histogram. Because `prestige` is a percentage, this behavior is not altogether unexpected. Variables such as this often need to be transformed, perhaps with a logit (log-odds) or similar transformation. But transforming `prestige` turns out to be unnecessary in this problem.\n\n::::\n:::::\n\nBefore fitting a regression model to the data, we should also examine the distributions of the predictors education and income, along with the relationship between prestige and each predictor, and the relationship between the two predictors.\n\n###### hist education\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-hist-education}\n: Histogram of `education` variable\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap01-hist-education}\n\n::: {.cell}\n\n```{.r .cell-code}\nd_01 |> \n    ggplot2::ggplot(\n        ggplot2::aes(x = education)\n    ) +\n    ggplot2::geom_histogram(\n        bins = 10,\n        color = \"white\",\n        fill = \"grey40\")\n```\n\n::: {.cell-output-display}\n![](01-getting-started_files/figure-html/hist-education-1.png){width=672}\n:::\n:::\n\nHistogram of education variable\n:::\n\n***\n\n\n::::\n:::::\n\n###### hist income\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-hist-income}\n: Histogram of `income` variable\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap01-hist-income}\n\n::: {.cell}\n\n```{.r .cell-code}\nd_01 |> \n    ggplot2::ggplot(\n        ggplot2::aes(x = income)\n    ) +\n    ggplot2::geom_histogram(\n        bins = 10,\n        color = \"white\",\n        fill = \"grey40\")\n```\n\n::: {.cell-output-display}\n![](01-getting-started_files/figure-html/hist-income-1.png){width=672}\n:::\n:::\n\nHistogram of income variable\n:::\n\n***\n\n\n::::\n:::::\n\n\n###### scatterplotMatrix\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-scatterplot-matrix}\n: Numbered R Code Title (Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap01-scatterplot-matrix}    \n\n::: {.cell}\n\n```{.r .cell-code}\ncar::scatterplotMatrix(\t~ prestige + education + income, \n                        id = list(n = 3), data = d_01)\n```\n\n::: {.cell-output-display}\n![](01-getting-started_files/figure-html/scatterplot-matrix-1.png){width=672}\n:::\n:::\n\n\nScatterplot matrix for prestige, education, and income in Duncan’s data, identifying the three most unusual points in each panel. Nonparametric density estimates for the variables appear in the diagonal panels, with a rug-plot (one-dimensional scatterplot) at the bottom of each diagonal panel.\n:::\n\n***\nThe `car::scatterplotMatrix()` function uses a one-sided formula to specify the variables to appear in the graph, where we read the formula `~ prestige + education + income` as “plot prestige and education and income.” \n\nThe argument `id = list(n = 3)` tells `scatterplotMatrix()` to identify the three most unusual points in each panel. This argument was added by the authors after examining a preliminary plot of the data.\n\n::: {.callout-warning #wrn-chap01-difference-in-scatterplot-matrix}\nIn contrast to Figure 1.10 my graph shows the three most unusual points in each panel with a number and not with the name of the occupation. I believe that this difference is a result of my recoding (changing row names into a column).\n:::\n\n::::\n:::::\n\n- **Nonparametric density estimates** are using an adaptive-kernel estimator, and they appear by default in the diagonal panels, with a *rug-plot* (“one-dimensional scatterplot”) at the bottom of each panel, showing the location of the data values for the corresponding variable.\n- The **solid line** shows the marginal linear least-squares fit for the regression of the vertical-axis variable (y) on the horizontal-axis variable (x), ignoring the other variables. \n- The **central broken line** is a nonparametric regression smooth, which traces how the average value of y changes as x changes without making strong assumptions about the form of the relationship between the two variables. \n- The **outer broken lines** represent smooths of the conditional variation of the y values given x in each panel, like running quartiles.\n\n::: {.callout-note #nte-chap01-spm-pairs-ggpairs}\n##### Is there a tidyverse equivalent for car::scatterplotMatrix()?\n\nI believe that `car::scatterplotMatrix()` is a modified `graphics::pairs()` function. `GGally::ggpairs()` is a {**ggplot2**} generalized [pairs plot matrix](https://ggobi.github.io/ggally/articles/ggpairs.html) equivalent in the tidyverse tradition. I should try it out and see if I can reproduce @lst-chap01-scatterplot-matrix with {**GGally**}.\n:::\n\nLike `prestige`, `education` appears to have a bimodal distribution. The distribution of `income`, in contrast, is perhaps best characterized as irregular. The pairwise relationships among the variables seem reasonably linear, which means that as we move from left to right across the plot, the average y values of the points more or less trace out a straight line. The scatter around the regression lines appears to have reasonably constant vertical variability and to be approximately symmetric.\n\nIn addition, two or three cases stand out from the others. In the scatterplot of `income` versus `education`, data point 6 (= ministers) are unusual in combining relatively low income with a relatively high level of education, and data point 16 (= conductors) and data point 27 (= railroad engineers) are unusual in combining relatively high levels of income with relatively low education. Because `education` and `income` are predictors in Duncan’s regression, these three occupations will have relatively high <a class='glossary' title='You can think of the regression line being balanced at the x-mean and the further from that location a point is, the more a single point can move the line. We can measure the distance of points from the mean to quantify each observation’s potential for impact on the line using what is called the leverage of a point. Leverage is a positive numerical measure with larger values corresponding to more leverage. The scale changes depending on the sample size (n) and the complexity of the model so all that matters is which observations have more or less relative leverage in a particular data set. (Outliers - leverage and influence)'>leverage</a> on the regression coefficients. None of these cases, however, are <a class='glossary' title='Outliers are observations with unusual values. (SwR, Glossary). Outliers are observed data points that are far from the least squares line. They have large “errors”, where the “error” or residual is the vertical distance from the line to the point. (Introductory Statistics 12.6)'>outliers</a> in the *univariate* distributions of the three variables.\n\n:::\n\n::::\n:::::\n\n### Regression Analysis\n\nFollowing Duncan, we next fit a linear least-squares regression to the data to model the joint dependence of prestige on the two predictors, under the assumption that the relationship of prestige to education and income is additive and linear.\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap01-ols-regression}\n: Compute OLS regression\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### fit lm.1\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-lm-1}\n: Fit linear model\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap01-lm-1}\n\n::: {.cell}\n\n```{.r .cell-code}\n(\n    lm01.1 <- stats::lm(\n        formula = prestige ~  education + income,\n        data = d_01\n    )\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> stats::lm(formula = prestige ~ education + income, data = d_01)\n#> \n#> Coefficients:\n#> (Intercept)    education       income  \n#>     -6.0647       0.5458       0.5987\n```\n\n\n:::\n:::\n\nRegress `prestige` on `education` and `income`\n:::\n\n::::\n:::::\n\n\n###### summary lm.1\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-summary-lm-1}\n: Summary of lm01.1\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap01-summary-lm-1}    \n\n::: {.cell}\n\n```{.r .cell-code}\nbase::summary(lm01.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> stats::lm(formula = prestige ~ education + income, data = d_01)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -29.538  -6.417   0.655   6.605  34.641 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)\n#> (Intercept) -6.06466    4.27194  -1.420    0.163\n#> education    0.54583    0.09825   5.555 1.73e-06\n#> income       0.59873    0.11967   5.003 1.05e-05\n#> \n#> Residual standard error: 13.37 on 42 degrees of freedom\n#> Multiple R-squared:  0.8282,\tAdjusted R-squared:   0.82 \n#> F-statistic: 101.2 on 2 and 42 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\nSummary of linear model where `prestige` is regressed on `education` and `income`\n:::\n\n***\n\nThe\t“statistical-significance” asterisks were suppressed with `options(show.signif.stars = FALSE)`.\n\n::::\n:::::\n\nBoth education and income have large regression coefficients in the \"Estimate\" column of the coefficient table, with small two-sided p-values in the column labeled \"Pr (>|t|)\". For example, holding education constant, a 1% increase in higher income earners is associated on average with an increase of about 0.6% in high prestige ratings.\n\n:::\n\n::::\n:::::\n\n### Regression diagnostics\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap01-regression-diagnostics}\n: Regression diagnostics\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### density\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-density-estimate}\n: Nonparametric density\testimate of the distribution of Studentized residuals\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap01-density-estimate}\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::densityPlot(stats::rstudent(lm01.1))\n```\n\n::: {.cell-output-display}\n![](01-getting-started_files/figure-html/density-estimate-1.png){width=672}\n:::\n:::\n\nNonparametric density estimate for the distribution of the Studentized residuals from the regression of `prestige` on `education` and `income.`\n:::\n\n***\nIf the errors in the regression are normally distributed with zero means and constant variance, then the Studentized residuals are each t-distributed with $n − k − 2$ degrees of freedom, where k is the number of coefficients in the model, excluding the regression constant, and n is the number of cases.\n\n::::\n:::::\n\n\n###### qqPlot\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-qq-plot}\n: Quantile-comparison plot for the Studentized residuals\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap01-qq-plot}    \n\n::: {.cell}\n\n```{.r .cell-code}\ncar::qqPlot(lm01.1, id = list(n = 3))\n```\n\n::: {.cell-output-display}\n![](01-getting-started_files/figure-html/qq-plot-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1]  6  9 17\n```\n\n\n:::\n:::\n\n\nQuantile-comparison plot for the Studentized residuals from the regression of prestige on education and income. The broken lines show a bootstrapped pointwise 95% confidence envelope for the points.\n:::\n***\n\nThe `car::qqPlot()` function extracts the Studentized residuals and plots them against the quantiles of the appropriate t-distribution. If the Studentized residuals are t-distributed, then the plotted points should lie close to a straight line. The solid comparison line on the plot is drawn by default by robust regression. The argument `id = list (n = 3)` identifies the three most extreme Studentized residuals, and `qqPlot()` returns the (names and) row numbers of these cases.\n\n(In my case the functions returns only the row numbers.)\n\n- 6 : minister\n- 9 : reporter\n- 17: contractor\n\n::: {.callout-warning #wrn-chap01-bootstrap-waiting-time}\nBe patient! The computation of the bootstrapped pointwise 95% confidence envelope for the points takes some time.\n:::\n\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n***\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}